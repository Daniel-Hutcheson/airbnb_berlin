{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the data to be analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_detailed_listings = pd.read_csv('./resource/detailed_listings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_listing_cleaned = df_detailed_listings.drop(columns=['listing_url', 'scrape_id', 'last_scraped', 'source', 'picture_url', 'host_url', \\\n",
    "#     'host_thumbnail_url', 'host_picture_url', 'latitude', 'longitude', 'calendar_updated', 'calendar_last_scraped', 'license'], \n",
    "#     axis=1).copy()\n",
    "# df_listing_cleaned = df_listing_cleaned.dropna(axis=1, how='all')\n",
    "# df_listing_cleaned['price'] = df_listing_cleaned.price.str[1:].str.replace(',','').str.split('.').str[0].astype(int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we try to train a model to predict the price of a listing. Therefor we need to prepare the data further:\n",
    "\n",
    "1) Drop all features which doesn't contain useful data for our model, such as URLs, dates and coordinates.\n",
    "2) Drop all entries with missing values for the respondent, in this case the price.\n",
    "3) If there are missing values for numerical features we fill them with the mean.\n",
    "4) For the categorical values we need to implement dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all features which doesn't contain useful data for our model, such as URLs, dates and personal information.\n",
    "df = df_detailed_listings.drop(columns=['id', 'host_id', 'listing_url', 'scrape_id', 'last_scraped', 'source', 'picture_url', 'host_url', \\\n",
    "    'host_thumbnail_url', 'host_picture_url', 'latitude', 'name', 'host_about', 'description', 'neighborhood_overview', 'host_name', 'longitude', 'calendar_updated', 'calendar_last_scraped', 'license'], \n",
    "    axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify the price column and change it into a usable integer datatype:\n",
    "df['price'] = df.price.str[1:].str.replace(',','').str.split('.').str[0].astype(int)\n",
    "\n",
    "# drop all entries with missing values for the respondent, in this case the price.\n",
    "df = df.dropna(subset=['price'], axis=0, how='all').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{int64: ['accommodates', 'price', 'minimum_nights', 'maximum_nights', 'minimum_minimum_nights', 'maximum_minimum_nights', 'minimum_maximum_nights', 'maximum_maximum_nights', 'availability_30', 'availability_60', 'availability_90', 'availability_365', 'number_of_reviews', 'number_of_reviews_ltm', 'number_of_reviews_l30d', 'calculated_host_listings_count', 'calculated_host_listings_count_entire_homes', 'calculated_host_listings_count_private_rooms', 'calculated_host_listings_count_shared_rooms'], float64: ['host_listings_count', 'host_total_listings_count', 'bathrooms', 'bedrooms', 'beds', 'minimum_nights_avg_ntm', 'maximum_nights_avg_ntm', 'review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication', 'review_scores_location', 'review_scores_value', 'reviews_per_month'], object: ['host_since', 'host_location', 'host_response_time', 'host_response_rate', 'host_acceptance_rate', 'host_is_superhost', 'host_neighbourhood', 'host_verifications', 'host_has_profile_pic', 'host_identity_verified', 'neighbourhood', 'neighbourhood_cleansed', 'neighbourhood_group_cleansed', 'property_type', 'room_type', 'bathrooms_text', 'amenities', 'has_availability', 'first_review', 'last_review', 'instant_bookable']}"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.to_series().groupby(df.dtypes).groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical features in the dataset: \n",
      "['host_listings_count', 'host_total_listings_count', 'accommodates', 'bathrooms', 'bedrooms', 'beds', 'price', 'minimum_nights', 'maximum_nights', 'minimum_minimum_nights', 'maximum_minimum_nights', 'minimum_maximum_nights', 'maximum_maximum_nights', 'minimum_nights_avg_ntm', 'maximum_nights_avg_ntm', 'availability_30', 'availability_60', 'availability_90', 'availability_365', 'number_of_reviews', 'number_of_reviews_ltm', 'number_of_reviews_l30d', 'review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication', 'review_scores_location', 'review_scores_value', 'calculated_host_listings_count', 'calculated_host_listings_count_entire_homes', 'calculated_host_listings_count_private_rooms', 'calculated_host_listings_count_shared_rooms', 'reviews_per_month']\n",
      "Categorical features in the dataset: \n",
      "['host_since', 'host_location', 'host_response_time', 'host_response_rate', 'host_acceptance_rate', 'host_is_superhost', 'host_neighbourhood', 'host_verifications', 'host_has_profile_pic', 'host_identity_verified', 'neighbourhood', 'neighbourhood_cleansed', 'neighbourhood_group_cleansed', 'property_type', 'room_type', 'bathrooms_text', 'amenities', 'has_availability', 'first_review', 'last_review', 'instant_bookable']\n"
     ]
    }
   ],
   "source": [
    "print(f'Numerical features in the dataset: \\n{list(df.select_dtypes([\"int\",\"float\"]).columns)}')\n",
    "print(f'Categorical features in the dataset: \\n{list(df.select_dtypes(\"object\").columns)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After prepping the data we split the dataset into the X Matrix and the respondent y, and further into sub-datasets used for training and testing the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df.price.isnull().sum())\n",
    "y = df.price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['price']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To fill in all missing values regarding the numeric features we loop through them \n",
    "# and use the fillna method to fill them with the mean of the column\n",
    "num_vars = X.select_dtypes(include=['float', 'int']).columns\n",
    "for col in num_vars:\n",
    "    X[col].fillna((X[col].mean()), inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of categorical features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of categorical features: 21\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15717, 54)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Number of categorical features: {len(X.select_dtypes(include='object').columns.to_list())}\")\n",
    "X.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Substitute all categorical features with dummy vaiables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars = X.select_dtypes(include=['object']).copy().columns\n",
    "for var in  cat_vars:\n",
    "    # for each cat add dummy var, drop original column\n",
    "    X = pd.concat([X.drop(var, axis=1), pd.get_dummies(X[var], prefix=var, prefix_sep='_', drop_first=True)], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get an overview over the new dimensions of the dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of categorical features: 0\n",
      "Dimensions of the dataframe: \n",
      "Features: 23952 - Rows: 15717\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of categorical features: {len(X.select_dtypes(include='object').columns.to_list())}\")\n",
    "print(f\"Dimensions of the dataframe: \\nFeatures: {X.shape[1]} - Rows: {X.shape[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
