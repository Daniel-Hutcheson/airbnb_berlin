{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the necessary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_detailed_listings = pd.read_csv('./resource/detailed_listings.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_detailed_reviews = pd.read_csv('./resource/raw_data/detailed_reviews.csv')\n",
    "# df_listings = pd.read_csv('./resource/raw_data/listings.csv')\n",
    "# df_reviews = pd.read_csv('./resource/raw_data/reviews.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview of the data - comparing detailed listings df to reduced listings df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_detailed_listings = df_detailed_listings.columns\n",
    "# columns_listings = df_listings.columns\n",
    "\n",
    "# detailed_listings_exclusive_features = [x for x in columns_detailed_listings if x not in columns_listings]\n",
    "# listings_exclusive_features = [x for x in columns_listings if x not in columns_detailed_listings]\n",
    "\n",
    "# print(f'Features which are only in the detailed listings csv: \\n{detailed_listings_exclusive_features}\\n')\n",
    "# print(f'Features which are only in the reduces listings csv: \\n{listings_exclusive_features}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently all columns from the reduced listings csv are included in the detailed listings csv, except for the column 'neighbourhood_group'. After looking through all column labels it is likely the information out of the 'neighbourhood_group' is also inlcuded in the detailed listings csv, but with a diffrent columnname."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_listings.neighbourhood_group.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_detailed_listings.neighbourhood_group_cleansed.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data regarding the 'neighbourhood_group' is also included in the detailed listings csv in the 'neighbourhood_group_cleansed' column. We therefore only need the detailed listings csv, without missing out on features regarding the listings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_detailed_reviews.info())\n",
    "# print(df_reviews.info())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the reviews and detailed reviews csv it becomes clear that the detailed reviews includes all informations necessary. For further analysis we focus on the detailed listings and detailed reviews csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_detailed_reviews.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_detailed_listings.info())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a look at the shape and dimensions of the two dataframes shows that there are way more reviews than listings, propably because there are multiple reviews for the same listings included in the review dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # comparing the entries of both lists and store the ones which aren't present in both to a new list via list comprehension:\n",
    "# # listings_without_reviews = [x for x in df_detailed_listings.id.unique() if x not in df_detailed_reviews.listing_id.unique()]\n",
    "# # print(f'listings without a review: {len(listings_without_reviews)}')\n",
    "\n",
    "# print(f'Unique IDs in the review df: {df_detailed_reviews.listing_id.nunique()}')\n",
    "# print(f'Unique IDs in the listings df: {df_detailed_listings.id.nunique()}')\n",
    "\n",
    "# # to save time computing this method of simply substracting the lists from each other is used. Both methods produce the same output.\n",
    "# print(f'Listings without a review: {df_detailed_listings.id.nunique() - df_detailed_reviews.listing_id.nunique()}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For further investigation of the data we merge the two dataframes on the respective ID columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # renaming the 'id' column into 'review_id':\n",
    "# df_r = df_detailed_reviews.rename(columns={'id': 'review_id'}).copy()\n",
    "\n",
    "# # renaming the 'id' column into 'listing_id':\n",
    "# df_l = df_detailed_listings.rename(columns={'id': 'listing_id'}).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doublecheck if everything went well\n",
    "# df_r.review_id.nunique(), df_detailed_reviews.id.nunique(), df_l.listing_id.nunique(), df_detailed_listings.id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.merge(df_l, df_r, on='listing_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'Shape of df_detailed_reviews: {df_detailed_reviews.shape}')\n",
    "# print(f'Shape of df_detailed_listings: {df_detailed_listings.shape}')\n",
    "# print(f'Shape of the merged dataframe df: {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doublecheck if the dataframes are merged correctly, using distinctive columns:\n",
    "# df.groupby(['listing_id'])[['listing_id', 'first_review', 'comments']].head(20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the raw, unplrocessed dataframe containing all data to analyze into a zipped csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('./resource/airbnb_berlin_data.csv.zip', index_label='listing_id', compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'listing_url', 'scrape_id', 'last_scraped', 'source', 'name',\n",
       "       'description', 'neighborhood_overview', 'picture_url', 'host_id',\n",
       "       'host_url', 'host_name', 'host_since', 'host_location', 'host_about',\n",
       "       'host_response_time', 'host_response_rate', 'host_acceptance_rate',\n",
       "       'host_is_superhost', 'host_thumbnail_url', 'host_picture_url',\n",
       "       'host_neighbourhood', 'host_listings_count',\n",
       "       'host_total_listings_count', 'host_verifications',\n",
       "       'host_has_profile_pic', 'host_identity_verified', 'neighbourhood',\n",
       "       'neighbourhood_cleansed', 'neighbourhood_group_cleansed', 'latitude',\n",
       "       'longitude', 'property_type', 'room_type', 'accommodates', 'bathrooms',\n",
       "       'bathrooms_text', 'bedrooms', 'beds', 'amenities', 'price',\n",
       "       'minimum_nights', 'maximum_nights', 'minimum_minimum_nights',\n",
       "       'maximum_minimum_nights', 'minimum_maximum_nights',\n",
       "       'maximum_maximum_nights', 'minimum_nights_avg_ntm',\n",
       "       'maximum_nights_avg_ntm', 'calendar_updated', 'has_availability',\n",
       "       'availability_30', 'availability_60', 'availability_90',\n",
       "       'availability_365', 'calendar_last_scraped', 'number_of_reviews',\n",
       "       'number_of_reviews_ltm', 'number_of_reviews_l30d', 'first_review',\n",
       "       'last_review', 'review_scores_rating', 'review_scores_accuracy',\n",
       "       'review_scores_cleanliness', 'review_scores_checkin',\n",
       "       'review_scores_communication', 'review_scores_location',\n",
       "       'review_scores_value', 'license', 'instant_bookable',\n",
       "       'calculated_host_listings_count',\n",
       "       'calculated_host_listings_count_entire_homes',\n",
       "       'calculated_host_listings_count_private_rooms',\n",
       "       'calculated_host_listings_count_shared_rooms', 'reviews_per_month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_detailed_listings.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw data containes a lot of information we do not want to process or use for predicting any features, so we drop them. For our purpose features which contain for example urls or similar should be droped befor starting to analyze the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_listing_cleaned = df_detailed_listings.drop(columns=['listing_url', 'scrape_id', 'last_scraped', 'source', 'picture_url', 'host_url', \\\n",
    "                                      'host_thumbnail_url', 'host_picture_url', 'latitude', 'longitude', 'calendar_updated', \\\n",
    "                                      'calendar_last_scraped', 'license'], axis=1).copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore there are also columns which contain no or way to few values to be valuable to our predictions and analysis. So they are droped as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['bathrooms'], dtype='object')\n",
      "62\n",
      "61\n"
     ]
    }
   ],
   "source": [
    "# Searching for columns missing all data:\n",
    "print(df_listing_cleaned.loc[:, df_listing_cleaned.isnull().all()].columns)\n",
    "\n",
    "# drop the column which has only missing values\n",
    "print(len(df_listing_cleaned.columns))\n",
    "df_listing_cleaned = df_listing_cleaned.dropna(axis=1, how='all')\n",
    "print(len(df_listing_cleaned.columns))\n",
    "\n",
    "# df_listing_cleaned = df_listing_cleaned.drop(columns=['bathrooms'], axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analyze = df_listing_cleaned.loc[:20]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "db9c059572ed3138442ca94ddfc11038f56d8174bb8c1e572332b95c07613972"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
